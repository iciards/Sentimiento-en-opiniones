{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcec9d87-38e7-4b4d-97d5-ff3aef72ae91",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/>\n",
    "\n",
    "<img src=\"https://uploads-ssl.webflow.com/614b1fe22fa8b90ef41aeffe/6265cb48f9496b1cefc9ab75_logotipo-mbit-39.png\" width=\"200px\" align=\"right\" CLASS=\"TextWrap\" style=\"background-color:#2a3f3f;\">\n",
    "\n",
    "<h1><font color=\"#2a3f3f\" size=5></font></h1>\n",
    "\n",
    "<br/>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#2a3f3f\" size=3>Javier Cózar - javier.cozar@mbitschool.com</font><br>\n",
    "<font color=\"#2a3f3f\" size=3>M07 - Proyecto de consolidación</font><br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e44c93",
   "metadata": {},
   "source": [
    "En este proyecto de consolidación vamos a aprender un modelo de detección del sentimiento utilizando MLlib. Una vez aprendido serializaremos el modelo en S3, lo que nos permitirá realizar predicciones siempre que queramos leyendo el modelo serializado con una simple instrucción.\n",
    "\n",
    "Para ello utilizaremos el dataset de [__amazon reviews__](https://s3.amazonaws.com/amazon-reviews-pds/readme.html) que antes estaba disponible de manera pública a través de un bucket de AWS S3, pero que han bloqueado el acceso por razones internas. En la siguiente URL podemos encontrar una versión del dataset público de amazon que contiene una gran cantidad de reviews generadas a lo largo de los años.\n",
    "\n",
    "https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/\n",
    "\n",
    "Puedes descargar el dataset original en la sección de **Files**. Sin embargo, para evitar descargar un dataset tan pesado, en la carpeta `data/amazon-reviews/` encontrarás un subset de los datos de la categoría `Electronics` en formato parquet. Debes subir esta carpeta a AWS S3 para poder trabajar con estos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21923a1-0671-4339-bbe6-f4cd63fb35cb",
   "metadata": {},
   "source": [
    "## Configuración de la sesión de glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4780e79-c8c0-4d87-8ec2-27bd46b75880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n",
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "It looks like there is a newer version of the kernel available. The latest version is 1.0.6 and you have 1.0.5 installed.\n",
      "Please run `pip install --upgrade aws-glue-sessions` to upgrade your kernel\n",
      "env: AWS_ACCESS_KEY_ID=ASIA5SKBQINMTICQRG2T\n",
      "env: AWS_SECRET_ACCESS_KEY=Bt+dAVuGy7y9zLBfVYqsIdcK81DS9Trizm9u/E/4\n",
      "env: AWS_SESSION_TOKEN=IQoJb3JpZ2luX2VjEKv//////////wEaCXVzLXdlc3QtMiJHMEUCIGYzJbwwiFtMEnxTUav0aDKp+AHT77Ru68POfqlsOfNEAiEAjdERYa5zEcOcZgDJzDrOHAAEb9kvYNd/g2cLIQw+Rg4qnwIINBABGgw5MzI2ODIxNTQ4NDEiDPPzaFhew7EVTiUYZir8ARIId2w0T/P3iQbN9OSzrq/ZAYa6/O7DW1GjHmRtGrb6eUD5BkRKAfgdsP3boq3w7BkzeM3DaJC53IeYkOsPi14fR43nn13gBf/3P6Ws0WMwB8rFWbDJeQuOVscWCZQS41M8UapW0cF+26XrvXNojK/1moSKkCQJcq3fXD7PvwkFn9BL/Hn7iBryrlB6ktnLkFurEq7cDRGVm4OKE9wCtq3nl4Vi0XQGb2N8Tm/6fSmZj0OJQSELX63viBc4Pym7o1S+0zmYEL9jKw2tOchR3iR2xSqxseMIe/fluxuvhrC6fp5czM29BSWDyYqX5sSYZYqWWpYYKGEhftGPBjCEkuOyBjqdAVWHxRJ4LzxyYfF2nSQ2gYB+DeJkZWP0Ylklok09ZPhZjhaJvGxdM9LaiO3PazXnBihDu2gLJUsIfjbheDwk0P/ylW5BLo7JWBHcFSK4Q1IcorJPSixLFqIoq3GVJH+ZmnJkmr8tyaHR6ELl74bKGbiEGldUdeFoUmkdEs5y1TpiSwngbqkrPsCJJC3fkXH9ol3mCHlrprcUSttn4GU=\n"
     ]
    }
   ],
   "source": [
    "%env AWS_ACCESS_KEY_ID=ASIA5SKBQINMTICQRG2T\n",
    "%env AWS_SECRET_ACCESS_KEY=Bt+dAVuGy7y9zLBfVYqsIdcK81DS9Trizm9u/E/4\n",
    "%env AWS_SESSION_TOKEN=IQoJb3JpZ2luX2VjEKv//////////wEaCXVzLXdlc3QtMiJHMEUCIGYzJbwwiFtMEnxTUav0aDKp+AHT77Ru68POfqlsOfNEAiEAjdERYa5zEcOcZgDJzDrOHAAEb9kvYNd/g2cLIQw+Rg4qnwIINBABGgw5MzI2ODIxNTQ4NDEiDPPzaFhew7EVTiUYZir8ARIId2w0T/P3iQbN9OSzrq/ZAYa6/O7DW1GjHmRtGrb6eUD5BkRKAfgdsP3boq3w7BkzeM3DaJC53IeYkOsPi14fR43nn13gBf/3P6Ws0WMwB8rFWbDJeQuOVscWCZQS41M8UapW0cF+26XrvXNojK/1moSKkCQJcq3fXD7PvwkFn9BL/Hn7iBryrlB6ktnLkFurEq7cDRGVm4OKE9wCtq3nl4Vi0XQGb2N8Tm/6fSmZj0OJQSELX63viBc4Pym7o1S+0zmYEL9jKw2tOchR3iR2xSqxseMIe/fluxuvhrC6fp5czM29BSWDyYqX5sSYZYqWWpYYKGEhftGPBjCEkuOyBjqdAVWHxRJ4LzxyYfF2nSQ2gYB+DeJkZWP0Ylklok09ZPhZjhaJvGxdM9LaiO3PazXnBihDu2gLJUsIfjbheDwk0P/ylW5BLo7JWBHcFSK4Q1IcorJPSixLFqIoq3GVJH+ZmnJkmr8tyaHR6ELl74bKGbiEGldUdeFoUmkdEs5y1TpiSwngbqkrPsCJJC3fkXH9ol3mCHlrprcUSttn4GU="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d7f208-3df8-45aa-8500-5240e739daeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iam_role is None\n",
      "iam_role has been set to arn:aws:iam::932682154841:role/LabRole.\n",
      "Previous region: None\n",
      "Setting new region to: us-east-1\n",
      "Region is set to: us-east-1\n",
      "Previous worker type: None\n",
      "Setting new worker type to: Standard\n",
      "Previous number of workers: None\n",
      "Setting new number of workers to: 2\n",
      "Current idle_timeout is None minutes.\n",
      "idle_timeout has been set to 120 minutes.\n"
     ]
    }
   ],
   "source": [
    "%iam_role arn:aws:iam::932682154841:role/LabRole\n",
    "%region us-east-1\n",
    "%worker_type Standard\n",
    "%number_of_workers 2\n",
    "%idle_timeout 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b50651-dd35-48ef-9d5b-5a22ffbee829",
   "metadata": {},
   "source": [
    "Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd97d19d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create a Glue session for the kernel.\n",
      "Session Type: etl\n",
      "Worker Type: Standard\n",
      "Number of Workers: 2\n",
      "Idle Timeout: 120\n",
      "Session ID: f9b279ce-34ab-40fa-9134-ddff27603e03\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 1.0.5\n",
      "--enable-glue-datacatalog true\n",
      "Waiting for session f9b279ce-34ab-40fa-9134-ddff27603e03 to get into ready status...\n",
      "Session f9b279ce-34ab-40fa-9134-ddff27603e03 has been created.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as f\n",
    "import re\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col, sum,  lower, regexp_replace\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.sql.functions import year, month\n",
    "from pyspark.sql.functions import to_date, split, lit, regexp_extract, concat\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab1aa6-7351-4b99-933b-7bfa4e6191a2",
   "metadata": {},
   "source": [
    "Define el nombre de tu bucket de S3 aquí, donde subiremos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90bf129e-250e-4aa2-b09f-1464c47ffa9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"pc3-mbit-iciardelossantos\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7be47",
   "metadata": {},
   "source": [
    "## Fase 1: Carga y análisis exploratorio\n",
    "\n",
    "Cargar el dataset a partir de los ficheros parquet y verificar el esquema. Muestra también las primeras filas del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75accd57",
   "metadata": {},
   "source": [
    "#### Carga los datos del bucket original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7020f89-35d0-490a-8d0c-7e2197ae6f06",
   "metadata": {},
   "source": [
    "Cargamos los 4 archivos a la vez de la carpeta amazon-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c90ed8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark\n",
    "    .read \n",
    "    .format(\"parquet\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(f\"s3://{BUCKET_NAME}/data/amazon-reviews/*.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe99d1c1-c037-4721-8e64-91df0348f4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[asin: string, overall: double, summary: string, reviewText: string, reviewTime: string, reviewerID: string, reviewerName: string, verified: boolean, vote: string, category: string]\n"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3a70d3-8683-4279-94ef-d985939e1171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- verified: boolean (nullable = true)\n",
      " |-- vote: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef225e0-0b34-42b8-a2dc-a91725b62519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+-----------+--------------+--------------------+--------+----+-----------+\n",
      "|      asin|overall|             summary|          reviewText| reviewTime|    reviewerID|        reviewerName|verified|vote|   category|\n",
      "+----------+-------+--------------------+--------------------+-----------+--------------+--------------------+--------+----+-----------+\n",
      "|B00009W3N5|    2.0|           Two Stars|Too wide! I shoul...|12 22, 2014|A1GRO2ZDN5II2C|               Glenn|    true|null|electronics|\n",
      "|B00008MN45|    3.0|         Three Stars|                fine|08 21, 2017|A27LEZ7ASH3OR9|         Neil Walter|    true|null|electronics|\n",
      "|B00006I53B|    5.0|          Five Stars|           very good| 10 6, 2015| AUTCUYOAQZTWT|  MILTON AGLIETTI P.|    true|null|electronics|\n",
      "|B00004XOND|    3.0|  Good for the money|This lens is a ni...|08 19, 2013|A2P9BH256LILMN|                  Jc|    true|   2|electronics|\n",
      "|B000068CNM|    5.0|6' cord makes thi...|Not much to comme...| 01 7, 2015| AM3Q2Y56OOLE6|        Brad Clayton|    true|null|electronics|\n",
      "|0972683275|    5.0|Strong/Easy insta...|This was perfect ...| 07 2, 2011|A3T3M5EYGCWSUA|             Mark T.|    true|null|electronics|\n",
      "|B00006B83F|    2.0|Not enough space ...|the  limited amou...|01 23, 2015|A3IHO7SYRRAGA8|            COOLPAPA|    true|null|electronics|\n",
      "|B00007AP2O|    5.0|        Works great.|Just got it for a...|11 26, 2015|A31QC2OMMZK3RE|Sebastian G. Sini...|    true|null|electronics|\n",
      "|B00018Q4GA|    5.0|        Great value!|These are an exce...|11 16, 2015|A36W40SJB30ZB5|          T. Spencer|    true|null|electronics|\n",
      "|B00004Z5PY|    5.0|Buying these was ...|With many USB cor...|03 30, 2013| AMZYVZBIMD7LY|      Richard Friese|    true|null|electronics|\n",
      "|B0000AI0N1|    5.0|        Good length.|Power strip met m...| 12 4, 2016|A3B06SWZ0PR0I6|     Amazon Customer|    true|null|electronics|\n",
      "|B00006HVWL|    3.0| Cheap feel..works..|Cheap constructio...|02 18, 2012| AUBEFRFHJR64Y|     SpeedingCheetah|    true|null|electronics|\n",
      "|B00004Z10L|    5.0|          Five Stars|Works well, price...| 07 8, 2015|A39419JWFB9OKA|            vickie b|    true|null|electronics|\n",
      "|B0000BZL0U|    5.0|       Great filter!|Excellent quality...| 06 1, 2013| AF0E2CNVCN7JM|                 K S|    true|null|electronics|\n",
      "|B00009KLAE|    2.0|Internal Reflections|This filter is fi...|06 16, 2006|A285VN49Q6UD7B|     Mark Nottingham|    true|null|electronics|\n",
      "|B00009UHXR|    4.0|Not affected by m...|I wasn't sure if ...|01 19, 2008|A1HT4X1GUTVDX7|          W. Costley|   false|   2|electronics|\n",
      "|B00007EDZG|    4.0|works as it shoul...|works as it shoul...|11 26, 2014|A3PZYF1GLPWU7V|               Scott|    true|null|electronics|\n",
      "|B0000668YX|    5.0|Works precisely a...|The one-star revi...|09 26, 2014| AOA7NY2649Z9I|    MyOnlineOpinions|    true|null|electronics|\n",
      "|B00009MVJM|    5.0|      Price is Right|This memory works...| 03 3, 2013|  A2L1HSS73VY7|             Michael|    true|null|electronics|\n",
      "|B00013M6NK|    5.0|Nikon EN-EL5 Rech...|This battery hold...|04 21, 2010|  A6IAVT91MBYN|         Avid Reader|    true|   4|electronics|\n",
      "+----------+-------+--------------------+--------------------+-----------+--------------+--------------------+--------+----+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83290dc",
   "metadata": {},
   "source": [
    "#### Cuenta el total de elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f26ac08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en df: 599973\n"
     ]
    }
   ],
   "source": [
    "print(f\"Registros en df: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8265b",
   "metadata": {},
   "source": [
    "### Análisis exploratorio\n",
    "\n",
    "Resuelve las siguientes cuestiones haciendo queries y también de manera gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe7ca7e",
   "metadata": {},
   "source": [
    "- Muestra el total de reviews para cada posible número de estrellas recibidas (`overall`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe9f32",
   "metadata": {},
   "source": [
    "- Obtén los 10 productos (columna `asin`) con más reviews mostrando numero de votos y valoración media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069fcfcc",
   "metadata": {},
   "source": [
    "- Obtén la cantidad de reviews por mes y año y su valoración media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc45f65-a789-4690-89d1-69fca92ffef0",
   "metadata": {},
   "source": [
    "##### Muestra el total de reviews para cada posible número de estrellas recibidas (overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bff8b4c7-65c8-4cd2-b33d-1ce38f9dd57e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|overall|total_reviews|\n",
      "+-------+-------------+\n",
      "|    1.0|        39868|\n",
      "|    2.0|        26839|\n",
      "|    3.0|        44377|\n",
      "|    4.0|       101991|\n",
      "|    5.0|       386898|\n",
      "+-------+-------------+\n"
     ]
    }
   ],
   "source": [
    "reviews = (\n",
    "    df\n",
    "    .select(\"overall\") #Seleccionamos la columna\n",
    "    .groupBy(\"overall\") #La agrupamos\n",
    "    .agg(\n",
    "        f.count(\"*\").alias(\"total_reviews\") \n",
    "    )\n",
    "    .orderBy(\"overall\")\n",
    ")\n",
    "\n",
    "reviews.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c9055-87e7-4c5c-ad9e-9e8c4876fb3c",
   "metadata": {},
   "source": [
    "##### Obtén los 10 productos (columna asin) con más reviews mostrando numero de votos y valoración media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7744b7-37f2-4b3a-ad4f-5820ba79ac36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------------------+-----------+\n",
      "|      asin|total_reviews|             media|total_votes|\n",
      "+----------+-------------+------------------+-----------+\n",
      "|B003L1ZYYW|          868| 4.768433179723503|          4|\n",
      "|B0019EHU8G|          817| 4.752753977968176|       null|\n",
      "|B0019HL8Q8|          807| 4.762081784386617|         12|\n",
      "|B0015DYMVO|          712| 4.252808988764045|         30|\n",
      "|B000VS4HDM|          680| 4.735294117647059|         13|\n",
      "|B000BQ7GW8|          630|  4.79047619047619|          4|\n",
      "|B00DIF2BO2|          621| 4.452495974235105|         26|\n",
      "|B00BWF5U0M|          607| 4.453047775947281|          8|\n",
      "|B00M55C0NS|          595| 4.719327731092437|          8|\n",
      "|B0043T7FXE|          592|4.5016891891891895|         17|\n",
      "+----------+-------------+------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "productos = (\n",
    "    df\n",
    "    .groupBy(\"asin\") \n",
    "    .agg(\n",
    "        f.count(\"*\").alias(\"total_reviews\"),\n",
    "        f.avg(\"overall\").alias(\"media\"),  \n",
    "        f.sum(f.when(f.col(\"vote\") != \"None\", 1)).alias(\"total_votes\")  \n",
    "    )  \n",
    ")\n",
    "\n",
    "top_10 = (\n",
    "    productos\n",
    "    .orderBy(f.desc(\"total_reviews\"))  \n",
    "    .limit(10)  \n",
    ")\n",
    "\n",
    "top_10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb31ab-59b4-4206-9467-33eee4dfec3a",
   "metadata": {},
   "source": [
    "#### Obtén la cantidad de reviews por mes y año y su valoración media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223bb8e-2d5b-46a3-8a9d-fb986478325d",
   "metadata": {},
   "source": [
    "Extraemos los valores del año y mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3008cf3-5d1e-48cd-aac7-a778afb9d20b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "df = df.withColumn(\"year\", substring(df[\"reviewTime\"], -4, 4)) \\\n",
    "       .withColumn(\"month\", substring(df[\"reviewTime\"], 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce96a72-b936-4847-a448-ef4eaebb028c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----+\n",
      "| reviewTime|year|month|\n",
      "+-----------+----+-----+\n",
      "|12 22, 2014|2014|   12|\n",
      "|08 21, 2017|2017|   08|\n",
      "| 10 6, 2015|2015|   10|\n",
      "|08 19, 2013|2013|   08|\n",
      "| 01 7, 2015|2015|   01|\n",
      "| 07 2, 2011|2011|   07|\n",
      "|01 23, 2015|2015|   01|\n",
      "|11 26, 2015|2015|   11|\n",
      "|11 16, 2015|2015|   11|\n",
      "|03 30, 2013|2013|   03|\n",
      "| 12 4, 2016|2016|   12|\n",
      "|02 18, 2012|2012|   02|\n",
      "| 07 8, 2015|2015|   07|\n",
      "| 06 1, 2013|2013|   06|\n",
      "|06 16, 2006|2006|   06|\n",
      "|01 19, 2008|2008|   01|\n",
      "|11 26, 2014|2014|   11|\n",
      "|09 26, 2014|2014|   09|\n",
      "| 03 3, 2013|2013|   03|\n",
      "|04 21, 2010|2010|   04|\n",
      "+-----------+----+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(\"reviewTime\", \"year\", \"month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a63889e4-4b87-4609-addf-313bd958110d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = (\n",
    "    df.\n",
    "    groupBy(\"year\", \"month\")\n",
    "    .agg(\n",
    "        f.count(\"overall\").alias(\"review_count\"),\n",
    "        f.avg(\"overall\").alias(\"average_rating\")\n",
    "    )  \n",
    ")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e4959",
   "metadata": {},
   "source": [
    "## Fase 2: Limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a2356",
   "metadata": {},
   "source": [
    "Antes de proseguir con el modelado realizaremos dos procesos de limpieza sobre los datos:\n",
    "\n",
    "- Limpiamos el texto de las reviews utilizando expresiones sobre strings o expresiones regulares\n",
    " - Pasar todo el texto a minusculas\n",
    " - Eliminar números y signos de puntuacion\n",
    "\n",
    "- Crearemos la variable `sentiment` en función del número de estrellas asumiendo que una review de menos de 3 estrellas es negativa, para poder generar la variable que determine el sentiment a partir del número de estrellas podéis utilizar la función de spark `when` \n",
    "\n",
    "- Visualiza el resultado estudiando alguna review suelta con su numero de estrellas correspondiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50928a-ac41-4e29-889f-4af7b279bfbe",
   "metadata": {},
   "source": [
    "Vamos a eleminar cualquier caracter que no sea alfabético o espacio. Convertimos el texto a minúsculas, eleminamos números y signos de puntuación y por último, dividimos el texto en palabras individuales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83655ce-c5be-417c-b8bd-cd30ff472cc7",
   "metadata": {},
   "source": [
    "Convertir todo el texto a minúsculas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "115df419-138b-4425-94dc-23bbb6a5a2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"reviewText\", lower(df[\"reviewText\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a835a67-3556-4341-a693-153bb59139d0",
   "metadata": {},
   "source": [
    "Eliminar números y signos de puntuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ec5467-2472-4ebd-a5f2-7b39083b2c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"reviewText\", regexp_replace(df[\"reviewText\"], \"[^a-zA-Z\\\\s]\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ff452-51aa-4e0f-bce9-a900df7a31e8",
   "metadata": {},
   "source": [
    "Comprobamos que la limpieza se ha realizado de forma correcta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11505513-0b8f-4a52-98b7-e020671e1d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|reviewText                                                                                                                                                                                                                                                                                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|too wide i should have measured the width before buying it also tape does not stay put                                                                                                                                                                                                                                                                        |\n",
      "|fine                                                                                                                                                                                                                                                                                                                                                          |\n",
      "|very good                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|this lens is a nice tele for beginners  it takes fairly crisp images with proper light  there is no stabilization so low light situations even evenings or shaded areas will require a tripod  the lens is quite heavy but that is to be expected  the build quality is a tad suspect  there is actually several small specs of dust on the inside of the lens|\n",
      "|not much to comment about on a surge protector but this one is nice has cord management built in and the foot cord is key most surge protectors have basic  cords which limit your placement  of cord is a really nice feature                                                                                                                                |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(\"reviewText\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355b1de-d8c3-440a-a5bc-bb19a6d7e807",
   "metadata": {},
   "source": [
    "Crearemos la variable sentiment en función del número de estrellas asumiendo que una review de menos de 3 estrellas es negativa, para poder generar la variable que determine el sentiment a partir del número de estrellas podéis utilizar la función de spark when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4fafd07-b523-46fd-ba9a-07261b5a364a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|overall|sentiment|\n",
      "+-------+---------+\n",
      "|    2.0| negativa|\n",
      "|    3.0| positiva|\n",
      "|    5.0| positiva|\n",
      "|    3.0| positiva|\n",
      "|    5.0| positiva|\n",
      "|    5.0| positiva|\n",
      "|    2.0| negativa|\n",
      "|    5.0| positiva|\n",
      "|    5.0| positiva|\n",
      "|    5.0| positiva|\n",
      "+-------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('sentiment', when(df['overall'] < 3, 'negativa').otherwise('positiva'))\n",
    "df.select('overall', 'sentiment').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc0c81-67a9-44f6-a094-324babf1b7cb",
   "metadata": {},
   "source": [
    "Antes debemos pasar la columna sentiments a valores enteros, en este caso 0 si es negativa y 1 si es positiva para poder entrenar el modelo correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2d29a60-b79a-472d-b3e6-6abf7ab69a79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|label|\n",
      "+---------+-----+\n",
      "| negativa|    0|\n",
      "| positiva|    1|\n",
      "| positiva|    1|\n",
      "| positiva|    1|\n",
      "| positiva|    1|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"label\", when(df[\"sentiment\"] == \"positiva\", 1).otherwise(0))\n",
    "df.select(\"sentiment\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6df7451-d5d5-4dd1-aee8-bce96086149f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|overall|num_estrellas|\n",
      "+-------+-------------+\n",
      "|    1.0|        39863|\n",
      "|    2.0|        26836|\n",
      "|    3.0|        44373|\n",
      "|    4.0|       101984|\n",
      "|    5.0|       386815|\n",
      "+-------+-------------+\n"
     ]
    }
   ],
   "source": [
    "estrellas= (\n",
    "    df\n",
    "    .groupBy('overall')\n",
    "    .agg(\n",
    "        f.count('*').alias('num_estrellas')\n",
    "    )\n",
    "    .orderBy('overall')\n",
    ")\n",
    "estrellas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72997003-2c3d-4969-bd1e-8f85bf76e2b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|sentiment|num_reseñas|\n",
      "+---------+-----------+\n",
      "| negativa|      66699|\n",
      "| positiva|     533172|\n",
      "+---------+-----------+\n"
     ]
    }
   ],
   "source": [
    "total_reseñas= (\n",
    "    df\n",
    "    .groupBy('sentiment')\n",
    "    .agg(\n",
    "        f.count('*').alias('num_reseñas')\n",
    "    )\n",
    ")\n",
    "total_reseñas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14953d-3e83-402f-af17-adef13b459fe",
   "metadata": {},
   "source": [
    "Visualiza el resultado estudiando alguna review suelta con su numero de estrellas correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfcd4c40-f33d-4ed1-8adc-ac7d7a2779e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de estrellas: 3.0\n",
      "Sentimiento: positiva\n",
      "Review:\n",
      "it works extremely well doing what its supposed to do but once i press the shutter button my keyboard wont show up anymore and i have to restart my phone\n"
     ]
    }
   ],
   "source": [
    "random_review = (\n",
    "    df\n",
    "    .select('overall', 'sentiment', 'reviewText')\n",
    "    .orderBy(rand())  # Ordenar de forma aleatoria\n",
    "    .limit(1)  # Seleccionar solo una revisión\n",
    "    .first()\n",
    ")\n",
    "\n",
    "print(\"Número de estrellas:\", random_review['overall'])\n",
    "print(\"Review:\", random_review['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca11ef92",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "Los datos están desbalanceados y el número de instancias es demasiado elevado. Para poderlo resolver vamos a realizar dos procesos:\n",
    "\n",
    "- Utiliza la función `sample_by` para muestrear el dataset y que quede el mismo número de elementos para cada clase.\n",
    "- Reduce el número de instancias para que haya en torno a 100k utiliza un nuevo muestreo o realizado junto con el anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86383d32-0808-40a0-879a-fa2d3fdbcad8",
   "metadata": {},
   "source": [
    "Jugamos con el código hasta que consigamos el resultado deseado, en torno a 100k filas, y que un 50% de los datos sea positivo y el otro 50% negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7294471d-8cc9-4131-bc0e-751db20ef0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160083\n",
      "+---------+------+\n",
      "|sentiment| count|\n",
      "+---------+------+\n",
      "| negativa| 53233|\n",
      "| positiva|106850|\n",
      "+---------+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sampled = df.sampleBy(\"sentiment\", fractions={\"negativa\": 0.8, \"positiva\": 0.2}, seed=42)\n",
    "sampled = sampled.sample(0.999999, seed=42)\n",
    "print(sampled.count())  \n",
    "print(sampled.groupBy(\"sentiment\").count().show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a822b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fase 3: Modelado\n",
    "\n",
    "A continuación vamos a entrenar el modelo, para ello utilizaremos diferentes opciones de preprocesamiento\n",
    "\n",
    "Para poder entrenar un clasificador de sentimiento necesitamos contruir una representación del texto que nos permita entrenar el modelo. Para ello utilizaremos un algoritmo de embedding como Word2Vec que viene implementado en Spark MLlib y que nos permitirá transformar una cadena de texto a un vector para utilizarlo como datos de entrenamiento de un clasificador. Este modelo viene definido como una serie de **transformadores** y **estimadores**\n",
    "\n",
    "- `Tokenizer` nos permitirá construir un vector de palabras a partir de nuestras sentencias\n",
    "- `StopWordsRemover` nos permitirá limpiar de nuestros vectores de palabras las de menor significado\n",
    "\n",
    "- Construcción de características dos alternativas\n",
    "    -  Modelo TF-IDF usando `HashingTF` e `IDF`\n",
    "    - `Word2Vec` nos permitirá crear un vector a partir de la lista de palabras\n",
    "\n",
    "- Clasificación binaria, basada en la variable sentiment que hemos utilizado, aplica un clasificador (LogisticRegregession, DecisionTree) evita ensembles por su alto tiempo de aprendizaje.\n",
    "\n",
    "Buscando en la documentación, encuentra los distintos elementos y conectalos en un pipeline junto a un algorimo de clasificación\n",
    "\n",
    "- Recomiendo utilizar una muestra pues el tiempo puede ser excesivo\n",
    "- Es posible ajustar hiperparámetros, pero igualmente puede ser bastante caro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bc335-0469-4b2f-833a-f37c1c706629",
   "metadata": {},
   "source": [
    "Creamos un tokenizer especificando la columna de entrada y la columna de salida y aplicamos al tokenizer al dataframe original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794fe5b4-c5d4-4ecb-8848-b70bc9bdf893",
   "metadata": {},
   "source": [
    "Comoprobamos la cantidad de nulos que hay en el dataframe para la columna revietext y luego procedemos a eliminarlos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9561c2ef-cbc4-4557-a2d8-85cfaf95fad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"reviewText\"].isNull() | f.isnan(df[\"reviewText\"])).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab0f0b39-65fa-4b88-96f5-2eca7f6e2aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"reviewText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeaed14-0d45-479a-9c60-7a3189966a89",
   "metadata": {},
   "source": [
    "Tokenizer nos permitirá construir un vector de palabras a partir de nuestras sentencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c45d3dbc-393c-4973-88db-9700c6ba86d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          reviewText|               words|\n",
      "+--------------------+--------------------+\n",
      "|too wide i should...|[too, wide, i, sh...|\n",
      "|                fine|              [fine]|\n",
      "|           very good|        [very, good]|\n",
      "|this lens is a ni...|[this, lens, is, ...|\n",
      "|not much to comme...|[not, much, to, c...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "df_tokenized = tokenizer.transform(df)\n",
    "df_tokenized.select(\"reviewText\", \"words\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7c661-29a8-427b-9265-6ee04735fb94",
   "metadata": {
    "tags": []
   },
   "source": [
    "StopWordsRemover nos permitirá limpiar de nuestros vectores de palabras las de menor significado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd35ef1c-5679-4523-9988-550d9c7f56bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|       filteredWords|\n",
      "+--------------------+--------------------+\n",
      "|[too, wide, i, sh...|[wide, measured, ...|\n",
      "|              [fine]|              [fine]|\n",
      "|        [very, good]|              [good]|\n",
      "|[this, lens, is, ...|[lens, nice, tele...|\n",
      "|[not, much, to, c...|[much, comment, s...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filteredWords\")\n",
    "df_filtered = remover.transform(df_tokenized)\n",
    "df_filtered.select(\"words\", \"filteredWords\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab91e4f-5f9a-48fe-bf8d-89f54c5a40c1",
   "metadata": {},
   "source": [
    "Modelo TF-IDF usando HashingTF e IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71b74e4c-5102-4280-bd1b-c470eb803a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec72d306-6869-4263-9168-c8656ee30fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|       filteredWords|            features|\n",
      "+--------------------+--------------------+\n",
      "|[wide, measured, ...|(262144,[30644,55...|\n",
      "|              [fine]|(262144,[245951],...|\n",
      "|              [good]|(262144,[113432],...|\n",
      "|[lens, nice, tele...|(262144,[1797,279...|\n",
      "|[much, comment, s...|(262144,[8664,163...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filteredWords\", outputCol=\"rawFeatures\")\n",
    "# HashingTF\n",
    "df_tf = hashingTF.transform(df_filtered)\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "df_tfidf = idf.fit(df_tf).transform(df_tf)\n",
    "df_tfidf.select(\"filteredWords\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cfaffd-1c80-4153-a790-3e3a79758784",
   "metadata": {},
   "source": [
    "Para poder juntar ambos dataframes agregamos una columna index a ambos y posteriormente unimos ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ca916b4-2c21-434b-9eee-c270b657bede",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+-----------+--------------+-------------+--------+----+-----------+----+-----+---------+-----+--------------------+--------------------+--------------------+\n",
      "|      asin|overall|             summary|          reviewText| reviewTime|    reviewerID| reviewerName|verified|vote|   category|year|month|sentiment|label|               words|       filteredWords|            features|\n",
      "+----------+-------+--------------------+--------------------+-----------+--------------+-------------+--------+----+-----------+----+-----+---------+-----+--------------------+--------------------+--------------------+\n",
      "|B00012VXV2|    5.0| Holy Cow, it WORKS!|i saw somewhere t...|09 29, 2011|A284G1BJHZ3285|   Patratacus|    true|  19|electronics|2011|   09| positiva|    1|[i, saw, somewher...|[saw, somewhere, ...|(262144,[7414,156...|\n",
      "|B00006I5EP|    5.0|Felxible, sturdy,...|great bag  easy t...|11 29, 2013| AQ0RLDXBQFL7M|            S|    true|null|electronics|2013|   11| positiva|    1|[great, bag, , ea...|[great, bag, , ea...|(262144,[25337,50...|\n",
      "|B00008XOH6|    4.0|    It works for me.|i wouldnt disagre...|06 26, 2007| AIL7BZH4932PN|         John|    true|   4|electronics|2007|   06| positiva|    1|[i, wouldnt, disa...|[wouldnt, disagre...|(262144,[6498,178...|\n",
      "|B00004X0ZG|    5.0|  A Quality Purchase|i have a cannon a...| 10 5, 2005|A17DFCNMGLNIXK|Narrowbigfoot|   false|null|electronics|2005|   10| positiva|    1|[i, have, a, cann...|[cannon, cannon, ...|(262144,[18270,43...|\n",
      "|B00004ZCJJ|    4.0|          Four Stars|               great|11 27, 2014|A3VJN3YRGNTHUC|   Ali Benzan|    true|null|electronics|2014|   11| positiva|    1|             [great]|             [great]|(262144,[261870],...|\n",
      "+----------+-------+--------------------+--------------------+-----------+--------------+-------------+--------+----+-----------+----+-----+---------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df_filtered.withColumn(\"index\", monotonically_increasing_id())\n",
    "df_tfidf = df_tfidf.withColumn(\"index\", monotonically_increasing_id())\n",
    "df_index = df_filtered.join(df_tfidf.select(\"index\", \"features\"), on=\"index\", how=\"inner\").drop(\"index\")\n",
    "df_index.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56448f9f-398d-4b17-8b45-ef79da27c7d9",
   "metadata": {},
   "source": [
    "Obtenemos una muestra de training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4357be6-5933-48e8-9f47-6f18d61ecd75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420039\n",
      "179832\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = df_index.randomSplit([0.7, 0.3], seed=1234)\n",
    "\n",
    "print(df_train.count())\n",
    "print(df_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05270c94-9c16-4302-b188-f2e83b5c7002",
   "metadata": {},
   "source": [
    "Aplicamos el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "984193a2-8afe-4355-bacc-29d014324c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(\n",
    "    labelCol=\"label\",  # Columna de etiquetas\n",
    "    featuresCol=\"features\",  # Columna de características\n",
    "    maxIter=20  # Número máximo de iteraciones\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ac2406f-264d-447d-972c-6dd377996b23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52177e30-0275-4ebc-9b71-9b069f0ac345",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 0.          1.38704559 -0.21875586 ...  0.          0.67907435\n",
      "  0.        ]\n",
      "Intercept: 2.021630\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: %s\" % (str(lr_model.coefficients.toArray())))\n",
    "\n",
    "print(\"Intercept: %f\" % (lr_model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6ea6d-ce5d-45a4-875e-c95e9db48229",
   "metadata": {},
   "source": [
    "Buscando en la documentación, encuentra los distintos elementos y conectalos en un pipeline junto a un algorimo de clasificación. Cogemos una muestra de df_train para que sea mas rápido. Eliminamos las columnas del tockenizador para que no nos de error al pasar el pipeline. Ajustamos el pipeline al dataframe y mostramos los resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af36a9a6-d9e0-403d-baf8-068258466bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+\n",
      "|          reviewText|sentiment|prediction|\n",
      "+--------------------+---------+----------+\n",
      "|first off they ar...| positiva|       1.0|\n",
      "|good things come ...| positiva|       1.0|\n",
      "|another one of th...| negativa|       0.0|\n",
      "|decent sound does...| negativa|       1.0|\n",
      "|just as described...| positiva|       1.0|\n",
      "|this will do the ...| positiva|       1.0|\n",
      "|they do what they...| positiva|       1.0|\n",
      "|good length not s...| positiva|       1.0|\n",
      "|this product is d...| positiva|       1.0|\n",
      "|as an amateur pho...| positiva|       1.0|\n",
      "|               great| positiva|       1.0|\n",
      "|fits the canon mm...| positiva|       1.0|\n",
      "|holds a lot works...| positiva|       1.0|\n",
      "|i am a profession...| positiva|       1.0|\n",
      "|there is nothing ...| negativa|       0.0|\n",
      "|talkback doesnt w...| negativa|       0.0|\n",
      "|i purchased these...| positiva|       1.0|\n",
      "|fast to ship item...| positiva|       1.0|\n",
      "|you simply cannot...| positiva|       1.0|\n",
      "|                  ok| positiva|       1.0|\n",
      "+--------------------+---------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "sample_df_train = df_train.sample(fraction=0.1, seed=1234)\n",
    "\n",
    "columns_to_drop = ['words', 'filteredWords', 'rawFeatures', 'features']\n",
    "for column in columns_to_drop:\n",
    "    if column in sample_df_train.columns:\n",
    "        sample_df_train = sample_df_train.drop(column)\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filteredWords\")\n",
    "hashingTF = HashingTF(inputCol=\"filteredWords\", outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])\n",
    "\n",
    "pipeline_model = pipeline.fit(sample_df_train)\n",
    "\n",
    "result = pipeline_model.transform(sample_df_train)\n",
    "\n",
    "result.select(\"reviewText\", \"sentiment\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86016afc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fase 4: Serializacion\n",
    "\n",
    "\n",
    "Una vez aprendido el modelo almacénalo en S3 utilizando tanto opción nativa de spark y así poderlo utilizar en el futuro.\n",
    "\n",
    "Finalmente, carga el modelo a partir de los datos serializados y haz una predicción sobre los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "527db5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"s3://{BUCKET_NAME}/mlmodel/mi_modelo1_pc7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "27083b59-c9f5-476d-98b9-5e0360bc95d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sc._jsc.hadoopConfiguration().set(\"mapred.output.committer.class\", \"org.apache.hadoop.mapred.DirectFileOutputCommitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb708357-8545-47df-b029-dfc5659f8ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a37e3-52cd-4f51-a841-af638445af34",
   "metadata": {},
   "source": [
    "Volvemos a repetir el proceso de eliminar las columnas que ya existen para que no nos de error y hacemos la prediccion en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afdab9da-c221-4ecd-8a62-9016a02b21ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['words', 'filteredWords', 'rawFeatures', 'features']\n",
    "for column in columns_to_drop:\n",
    "    if column in df_test.columns:\n",
    "        df_test = df_test.drop(column)\n",
    "        \n",
    "loaded_model = PipelineModel.load(model_path)\n",
    "predictions = loaded_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd85d47-7436-4070-8b0e-1804a37dbb27",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Opcional\n",
    "\n",
    "Con la columna de predictions y de sentiments, prueba a quedarte con unas cuantas filas que la predicción sea erronea (sentiment distinto de prediction), recolectalas con Pandas para una evaluación más cómoda y visualiza los textos. ¿Tienen sentido? :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba47968d-8111-4f1a-9883-85fea4cb1b62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "incorrect_predictions = predictions.filter(predictions.sentiment != predictions.prediction).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ad40567b-4f50-401f-b7a2-b59bef84993a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_df = incorrect_predictions.select(\"reviewText\", \"sentiment\", \"prediction\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b0949221-b8bf-4a14-bdd6-cb5ebf37f915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [reviewText, sentiment, prediction]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ac0220a-9141-4bbc-aa24-556e05c79a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df[\"reviewText\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3377ce2-485a-432c-8fb9-eac75fab10da",
   "metadata": {},
   "source": [
    "Que no aparezca ningún dato quiere decir que hemos entrenado correctamente "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
